"""
DeepSeek-OCR Web UI Backend
ä½¿ç”¨ Docker vLLM API è¿›è¡Œ OCR è¯†åˆ«
"""

import uuid
import asyncio
import shutil
from pathlib import Path
from typing import Optional
from fastapi import FastAPI, UploadFile, File, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import requests
import fitz  # PyMuPDF
import json

app = FastAPI(title="DeepSeek OCR Web UI", version="1.0.0")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®
import os
UPLOAD_DIR = Path("uploads")
RESULTS_DIR = Path("results")
LOGS_DIR = Path("logs")
WORKSPACE_DIR = Path(os.getenv("WORKSPACE_DIR", "/workspace"))
VLLM_API_URL = os.getenv("VLLM_API_URL", "http://localhost:8000/v1/chat/completions")

# åˆ›å»ºç›®å½•
for dir_path in [UPLOAD_DIR, RESULTS_DIR, LOGS_DIR, WORKSPACE_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

# WebSocket è¿æ¥ç®¡ç†
active_connections = {}


# ============ å·¥å…·å‡½æ•° ============

def save_task_state(task_id: str, state: dict):
    """ä¿å­˜ä»»åŠ¡çŠ¶æ€"""
    state_file = LOGS_DIR / f"task_{task_id}.json"
    state_file.write_text(json.dumps(state, indent=2, ensure_ascii=False), encoding='utf-8')


def load_task_state(task_id: str) -> Optional[dict]:
    """åŠ è½½ä»»åŠ¡çŠ¶æ€"""
    state_file = LOGS_DIR / f"task_{task_id}.json"
    if not state_file.exists():
        return None
    return json.loads(state_file.read_text(encoding='utf-8'))


def pdf_to_images(pdf_path: Path, output_dir: Path) -> list:
    """PDF è½¬å›¾ç‰‡"""
    output_dir.mkdir(parents=True, exist_ok=True)
    pdf = fitz.open(str(pdf_path))
    image_paths = []
    
    for page_num in range(pdf.page_count):
        page = pdf[page_num]
        zoom = 2.0
        matrix = fitz.Matrix(zoom, zoom)
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        
        img_path = output_dir / f"page_{page_num}.png"
        pixmap.save(str(img_path))
        image_paths.append(img_path)
    
    pdf.close()
    return image_paths


def call_vllm_api(image_path: Path, prompt: str) -> dict:
    """è°ƒç”¨ vLLM API"""
    # å¤åˆ¶å›¾ç‰‡åˆ° workspace
    workspace_img = WORKSPACE_DIR / image_path.name
    shutil.copy(image_path, workspace_img)
    
    payload = {
        "model": "deepseek-ocr",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"file:///workspace/{workspace_img.name}"}},
                {"type": "text", "text": prompt}
            ]
        }],
        "max_tokens": 4096,
        "temperature": 0
    }
    
    response = requests.post(VLLM_API_URL, json=payload, timeout=120)
    response.raise_for_status()
    result = response.json()
    
    return {
        "text": result['choices'][0]['message']['content'],
        "usage": result.get('usage', {})
    }


async def update_progress(task_id: str, progress: int):
    """æ›´æ–°è¿›åº¦"""
    if task_id in active_connections:
        try:
            await active_connections[task_id].send_json({
                "task_id": task_id,
                "progress": progress
            })
        except:
            pass


# ============ API ç«¯ç‚¹ ============

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        response = requests.get("http://deepseek-ocr:8000/health", timeout=5)
        vllm_status = "running" if response.status_code == 200 else "error"
    except:
        vllm_status = "error"
    
    return {
        "backend": "running",
        "vllm": vllm_status
    }


@app.get("/api/model/status")
async def model_status():
    """æ£€æŸ¥æ¨¡å‹åŠ è½½çŠ¶æ€"""
    try:
        # æ£€æŸ¥ vLLM health (ä½¿ç”¨å®¹å™¨åè€Œä¸æ˜¯localhost)
        health_response = requests.get("http://deepseek-ocr:8000/health", timeout=5)
        if health_response.status_code != 200:
            return {
                "status": "loading",
                "ready": False,
                "message": "vLLM æœåŠ¡æœªå°±ç»ª,æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­..."
            }
        
        # æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
        models_response = requests.get("http://deepseek-ocr:8000/v1/models", timeout=5)
        if models_response.status_code == 200:
            models_data = models_response.json()
            if models_data.get("data") and len(models_data["data"]) > 0:
                return {
                    "status": "ready",
                    "ready": True,
                    "message": "æ¨¡å‹å·²åŠ è½½å®Œæˆ",
                    "model": models_data["data"][0].get("id", "deepseek-ocr")
                }
        
        return {
            "status": "loading",
            "ready": False,
            "message": "æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­,è¯·ç¨å€™..."
        }
    except requests.exceptions.ConnectionError:
        # è¿æ¥è¢«æ‹’ç»é€šå¸¸æ„å‘³ç€æœåŠ¡æ­£åœ¨å¯åŠ¨
        return {
            "status": "loading",
            "ready": False,
            "message": "æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­,é¢„è®¡éœ€è¦ 30-60 ç§’..."
        }
    except requests.exceptions.Timeout:
        # è¶…æ—¶ä¹Ÿå¯èƒ½æ˜¯æœåŠ¡æ­£åœ¨å¯åŠ¨
        return {
            "status": "loading",
            "ready": False,
            "message": "æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­,è¯·è€å¿ƒç­‰å¾…..."
        }
    except Exception as e:
        # å…¶ä»–æœªçŸ¥é”™è¯¯æ‰æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        error_str = str(e)
        # å¦‚æœæ˜¯è¿æ¥ç›¸å…³é”™è¯¯,æ˜¾ç¤ºå‹å¥½æç¤º
        if "Connection refused" in error_str or "Failed to establish" in error_str:
            return {
                "status": "loading",
                "ready": False,
                "message": "æ¨¡å‹æ­£åœ¨å¯åŠ¨ä¸­,è¯·ç¨å€™..."
            }
        # çœŸæ­£çš„é”™è¯¯æ‰æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        return {
            "status": "error",
            "ready": False,
            "message": f"æœåŠ¡å¼‚å¸¸: {error_str}"
        }


@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """ä¸Šä¼ æ–‡ä»¶"""
    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        file_ext = Path(file.filename).suffix
        unique_filename = f"{uuid.uuid4().hex[:8]}{file_ext}"
        file_path = UPLOAD_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # æ£€æµ‹æ–‡ä»¶ç±»å‹
        file_type = "pdf" if file_ext.lower() == ".pdf" else "image"
        
        return {
            "status": "success",
            "file_path": str(file_path),
            "file_type": file_type,
            "filename": file.filename
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.post("/api/ocr")
async def start_ocr(payload: dict, background_tasks: BackgroundTasks):
    """å¯åŠ¨ OCR ä»»åŠ¡"""
    file_path = payload.get("file_path")
    prompt = payload.get("prompt", "<image>\nFree OCR.")
    file_type = payload.get("file_type", "image")
    
    if not file_path or not Path(file_path).exists():
        return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨"}
    
    task_id = uuid.uuid4().hex[:8]
    result_dir = RESULTS_DIR / f"task_{task_id}"
    result_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜åˆå§‹çŠ¶æ€
    save_task_state(task_id, {
        "status": "running",
        "progress": 0,
        "result_dir": str(result_dir)
    })
    
    async def process_task():
        try:
            if file_type == "pdf":
                # PDF å¤„ç†
                await update_progress(task_id, 10)
                
                # è½¬æ¢ä¸ºå›¾ç‰‡
                images_dir = result_dir / "images"
                image_paths = pdf_to_images(Path(file_path), images_dir)
                total_pages = len(image_paths)
                
                results = []
                for idx, img_path in enumerate(image_paths):
                    progress = 20 + int((idx / total_pages) * 70)
                    await update_progress(task_id, progress)
                    
                    result = call_vllm_api(img_path, prompt)
                    results.append({
                        "page": idx + 1,
                        "text": result['text']
                    })
                
                # åˆå¹¶ç»“æœ
                full_text = "\n\n<--- Page Split --->\n\n".join([r['text'] for r in results])
                output_file = result_dir / "result.md"
                output_file.write_text(full_text, encoding='utf-8')
                
                save_task_state(task_id, {
                    "status": "finished",
                    "progress": 100,
                    "result_dir": str(result_dir),
                    "output_file": str(output_file),
                    "total_pages": total_pages
                })
            else:
                # å›¾ç‰‡å¤„ç†
                await update_progress(task_id, 20)
                
                result = call_vllm_api(Path(file_path), prompt)
                
                await update_progress(task_id, 80)
                
                output_file = result_dir / "result.txt"
                output_file.write_text(result['text'], encoding='utf-8')
                
                save_task_state(task_id, {
                    "status": "finished",
                    "progress": 100,
                    "result_dir": str(result_dir),
                    "output_file": str(output_file)
                })
            
            await update_progress(task_id, 100)
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            if task_id in active_connections:
                await active_connections[task_id].send_json({
                    "task_id": task_id,
                    "status": "finished"
                })
        
        except Exception as e:
            save_task_state(task_id, {
                "status": "error",
                "message": str(e)
            })
            if task_id in active_connections:
                await active_connections[task_id].send_json({
                    "task_id": task_id,
                    "status": "error",
                    "message": str(e)
                })
    
    background_tasks.add_task(process_task)
    return {"status": "running", "task_id": task_id}


@app.get("/api/result/{task_id}")
async def get_result(task_id: str):
    """è·å–ä»»åŠ¡ç»“æœ"""
    state = load_task_state(task_id)
    if not state:
        return {"status": "error", "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
    
    if state["status"] == "finished":
        output_file = Path(state["output_file"])
        if output_file.exists():
            content = output_file.read_text(encoding='utf-8')
            return {
                "status": "success",
                "task_id": task_id,
                "content": content,
                "output_file": str(output_file)
            }
    
    return state


@app.websocket("/ws/{task_id}")
async def websocket_endpoint(websocket: WebSocket, task_id: str):
    """WebSocket è¿›åº¦æ¨é€"""
    await websocket.accept()
    active_connections[task_id] = websocket
    print(f"ğŸŒ WebSocket è¿æ¥: {task_id}")
    
    try:
        while True:
            await asyncio.sleep(1)
    except WebSocketDisconnect:
        print(f"âŒ WebSocket æ–­å¼€: {task_id}")
        if task_id in active_connections:
            del active_connections[task_id]


# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/results", StaticFiles(directory=str(RESULTS_DIR)), name="results")


@app.get("/")
async def serve_index():
    """æä¾› Web UI é¦–é¡µ"""
    html_file = Path(__file__).parent / "static" / "index.html"
    if html_file.exists():
        return FileResponse(html_file)
    return {"message": "DeepSeek OCR Web UI Backend", "status": "running"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
