# DeepSeek-OCR Docker éƒ¨ç½²æŒ‡å—

åŸºäº vLLM å®˜æ–¹ nightly é•œåƒçš„ DeepSeek-OCR ç¦»çº¿éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒæœ¬åœ° RTX 5090 å’Œè¿œç¨‹ H100 æœåŠ¡å™¨ã€‚

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
DeepSeek-OCR/
â”œâ”€â”€ docker-compose.yml          # æœ¬åœ° 5090 ç”Ÿäº§ç¯å¢ƒé…ç½®
â”œâ”€â”€ docker-compose.h100.yml     # H100 æœåŠ¡å™¨ç”Ÿäº§ç¯å¢ƒé…ç½®
â”œâ”€â”€ Dockerfile.vllm             # åç«¯æœåŠ¡ Dockerfile (åŸºäº vLLM nightly)
â”œâ”€â”€ Dockerfile.webui            # å‰ç«¯æœåŠ¡ Dockerfile
â”œâ”€â”€ models/                     # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”œâ”€â”€ workspace/                  # å·¥ä½œåŒºç›®å½•
â””â”€â”€ web-ui/                     # Web UI æºç 
    â”œâ”€â”€ backend/                # åç«¯ API
    â””â”€â”€ frontend/               # å‰ç«¯é¡µé¢
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ¬åœ°éƒ¨ç½² (RTX 5090)

```bash
# 1. æ„å»ºé•œåƒ
docker build -t deepseek-ocr:h100 -f Dockerfile.vllm .
docker build -t deepseek-ocr-deepseek-web:latest -f Dockerfile.webui .

# 2. å¯åŠ¨æœåŠ¡
docker compose up -d

# 3. æŸ¥çœ‹æ—¥å¿—
docker compose logs -f

# 4. è®¿é—®æœåŠ¡
# åç«¯ API: http://localhost:8000
# å‰ç«¯ Web UI: http://localhost:8002
```

### H100 æœåŠ¡å™¨éƒ¨ç½²

```bash
# ä½¿ç”¨ H100 ä¸“ç”¨é…ç½®
docker compose -f docker-compose.h100.yml up -d
docker compose -f docker-compose.h100.yml logs -f
```

## ğŸ“¦ ç¦»çº¿éƒ¨ç½²æµç¨‹

### 1. æœ¬åœ°å‡†å¤‡ (RTX 5090)

```bash
# å¯¼å‡º Docker é•œåƒ
docker save deepseek-ocr:h100 -o deepseek-ocr-h100.tar
docker save deepseek-ocr-deepseek-web:latest -o deepseek-web.tar

# å‡†å¤‡éƒ¨ç½²æ–‡ä»¶
# - deepseek-ocr-h100.tar (~17GB)
# - deepseek-web.tar (~200MB)
# - docker-compose.h100.yml
# - models/ ç›®å½• (å¦‚æœ H100 æœåŠ¡å™¨æ²¡æœ‰æ¨¡å‹æ–‡ä»¶)
```

### 2. H100 æœåŠ¡å™¨éƒ¨ç½²

```bash
# åŠ è½½é•œåƒ
docker load -i deepseek-ocr-h100.tar
docker load -i deepseek-web.tar

# éªŒè¯é•œåƒ
docker images | grep deepseek

# å¯åŠ¨æœåŠ¡
docker compose -f docker-compose.h100.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker compose -f docker-compose.h100.yml logs -f deepseek-ocr
```

## âš™ï¸ é…ç½®è¯´æ˜

### æœ¬åœ°é…ç½® (docker-compose.yml)

- **GPU**: ç¬¬ 0 å— GPU
- **GPU åˆ©ç”¨ç‡**: 90%
- **åç«¯ç«¯å£**: 8000
- **å‰ç«¯ç«¯å£**: 8002
- **æ¨¡å‹è·¯å¾„**: `./models` (åªè¯»æŒ‚è½½)
- **å·¥ä½œåŒº**: `./workspace`

### H100 é…ç½® (docker-compose.h100.yml)

- **GPU**: ç¬¬ 3 å— GPU
- **GPU åˆ©ç”¨ç‡**: 95%
- **å…¶ä»–é…ç½®**: ä¸æœ¬åœ°é…ç½®ç›¸åŒ

## ğŸ”§ æŠ€æœ¯æ ˆ

### åç«¯æœåŠ¡
- **åŸºç¡€é•œåƒ**: vLLM nightly (sha256:f32c2d7673b8a6fdece522f5cc7de4755c35eb3a315d3ad39767e004f9cf70b0)
- **æ¨ç†å¼•æ“**: vLLM v0.11.1rc6+
- **æ¨¡å‹**: DeepSeek-OCR
- **é¢å¤–ä¾èµ–**: PyMuPDF, img2pdf, einops, matplotlib, timm

### å‰ç«¯æœåŠ¡
- **åŸºç¡€é•œåƒ**: python:3.11-slim
- **æ¡†æ¶**: FastAPI + Uvicorn
- **ä¾èµ–**: python-multipart, PyMuPDF, requests, websockets

## ğŸ“ å…³é”®å‚æ•°è¯´æ˜

### vLLM å¯åŠ¨å‚æ•°

```yaml
command:
  - /workspace/models                    # æ¨¡å‹è·¯å¾„
  - --served-model-name                  # æ¨¡å‹æœåŠ¡åç§°
  - deepseek-ocr
  - --logits_processors                  # è‡ªå®šä¹‰ logits å¤„ç†å™¨
  - vllm.model_executor.models.deepseek_ocr:NGramPerReqLogitsProcessor
  - --no-enable-prefix-caching           # ç¦ç”¨å‰ç¼€ç¼“å­˜
  - --mm-processor-cache-gb              # å¤šæ¨¡æ€å¤„ç†å™¨ç¼“å­˜
  - "0"
  - --gpu-memory-utilization             # GPU æ˜¾å­˜åˆ©ç”¨ç‡
  - "0.9"                                # æœ¬åœ° 90%, H100 95%
  - --allowed-local-media-path           # å…è®¸è®¿é—®çš„æœ¬åœ°åª’ä½“è·¯å¾„
  - /workspace
  - --trust-remote-code                  # ä¿¡ä»»è¿œç¨‹ä»£ç 
```

## ğŸ” å¸¸è§é—®é¢˜

### 1. æ¨¡å‹åŠ è½½æ—¶é—´
- é¦–æ¬¡å¯åŠ¨éœ€è¦ 30-60 ç§’åŠ è½½æ¨¡å‹
- å¯é€šè¿‡å¥åº·æ£€æŸ¥ç¡®è®¤æœåŠ¡å°±ç»ª: `curl http://localhost:8000/health`

### 2. GPU æ˜¾å­˜ä¸è¶³
- è°ƒæ•´ `--gpu-memory-utilization` å‚æ•° (é»˜è®¤ 0.9)
- ç¡®ä¿ GPU æ˜¾å­˜è‡³å°‘ 16GB

### 3. å‰ç«¯è¿æ¥å¤±è´¥
- ç¡®è®¤åç«¯æœåŠ¡å·²å¯åŠ¨: `docker compose ps`
- æ£€æŸ¥åç«¯æ—¥å¿—: `docker compose logs deepseek-ocr`
- éªŒè¯æ¨¡å‹åç§°: `curl http://localhost:8000/v1/models`

### 4. å®¹å™¨é‡å¯å¾ªç¯
- æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: `docker logs <container_name>`
- æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨: `nvidia-smi`
- ç¡®è®¤æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

## ğŸ“Š æ€§èƒ½å‚è€ƒ

### RTX 5090 Laptop GPU
- **æ˜¾å­˜**: 16GB
- **KV Cache**: 236,704 tokens
- **å¹¶å‘èƒ½åŠ›**: 28.89x (8192 tokens/request)
- **æ¨¡å‹åŠ è½½**: ~7 ç§’
- **åˆå§‹åŒ–æ—¶é—´**: ~35 ç§’

### H100
- **æ˜¾å­˜**: 80GB
- **æ¨è GPU åˆ©ç”¨ç‡**: 95%
- **é€‚åˆç”Ÿäº§ç¯å¢ƒé«˜å¹¶å‘åœºæ™¯**

## ğŸ› ï¸ æœåŠ¡ç®¡ç†

```bash
# å¯åŠ¨æœåŠ¡
docker compose up -d

# åœæ­¢æœåŠ¡
docker compose down

# é‡å¯æœåŠ¡
docker compose restart

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose ps

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker compose logs -f deepseek-ocr
docker compose logs -f deepseek-web
```

## ğŸ“š API æ–‡æ¡£

å¯åŠ¨æœåŠ¡åè®¿é—®:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ”— ç›¸å…³é“¾æ¥

- [DeepSeek-OCR å®˜æ–¹ä»“åº“](https://github.com/deepseek-ai/DeepSeek-OCR)
- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [vLLM Docker Hub](https://hub.docker.com/r/vllm/vllm-openai)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request!

---

**æ³¨æ„**: æœ¬éƒ¨ç½²æ–¹æ¡ˆåŸºäº vLLM nightly æ„å»ºï¼Œé€‚ç”¨äºç¦»çº¿ç¯å¢ƒã€‚ç¡®ä¿åœ¨éƒ¨ç½²å‰å®Œæˆæ‰€æœ‰é•œåƒå’Œæ¨¡å‹æ–‡ä»¶çš„å‡†å¤‡å·¥ä½œã€‚
